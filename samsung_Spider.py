# -*- coding: utf-8 -*-
import scrapy
from samsung.items import SamsungItem

def getCleanStartUrlList(filename):
    """
    Takes as input the name of the txt file generated by next
    script. In this file each line is the url of a blog post published 
    in the period (1 January 2008 - 15 August 2014). The function returns
    a list of all the urls to be scraped.
    """
    myfile = open(filename, "r")
    urls = myfile.readlines()
    lst = []
    return [url.strip() for url in urls]

class SamsungSpiderSpider(scrapy.Spider):
    name = 'samsung_Spider'
    allowed_domains = ['http://www.reuters.com/']
    
    urls = getCleanStartUrlList('url_list.txt')

    start_urls = urls

    def parse(self, response):
        item = SamsungItem()
 
        # item['date'] = urls[-10:-2]
        item['Date'] = response.xpath('//meta[@property="og:url"]/@content').extract()
        item['Title'] = response.xpath('//div[@class="feature"]/h2/a/text() | //div[@class="topStory"]/h2/a/text() ').extract()
        item['Body'] = response.xpath('//div[@class="feature"]/p/text() | //div[@class="topStory"]/p/text()').extract()
        yield item
    
